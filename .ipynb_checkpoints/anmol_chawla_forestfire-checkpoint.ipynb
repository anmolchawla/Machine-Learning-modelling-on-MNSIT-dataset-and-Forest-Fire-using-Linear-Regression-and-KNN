{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project : Forest Fire\n",
    "The aim is to predict the burned area of forest in the northeast region of Portugal. \n",
    "Data Set Obtained From: https://archive.ics.uci.edu/ml/datasets/\n",
    "Forest+Fires\n",
    "The notebook analyzes the dataset using Linear Regression, Multivariate Regression and KNN Regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data and importing dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0840e04cc34a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotnull\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_eng_float_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m from pandas.core.index import (Index, CategoricalIndex, Int64Index,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m from pandas.core.base import (PandasObject, SelectionMixin, GroupByError,\n\u001b[0;32m     45\u001b[0m                               DataError, SpecificationError)\n\u001b[1;32m---> 46\u001b[1;33m from pandas.core.index import (Index, MultiIndex,\n\u001b[0m\u001b[0;32m     47\u001b[0m                                CategoricalIndex, _ensure_index)\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\index.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# flake8: noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_sparsify\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m from pandas.core.indexes.base import (Index, _new_Index,  # noqa\n\u001b[0m\u001b[0;32m      2\u001b[0m                                  \u001b[0m_ensure_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_get_na_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                  InvalidIndexError)\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategoricalIndex\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPandasObject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexOpsMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m from pandas.util._decorators import (Appender, Substitution, cache_readonly,\n\u001b[0;32m     45\u001b[0m                                      deprecate, deprecate_kwarg)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange\n",
    "import seaborn as sb\n",
    "import statistics\n",
    "import math\n",
    "import itertools \n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "data =pd.read_csv('forestfires.csv', sep=',')\n",
    "print(data[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B (i)\n",
    "There seem to be 517 instances with 12 attributes and one result attribute.\n",
    "   1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    "   2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    "   3. month - month of the year: \"jan\" to \"dec\" \n",
    "   4. day - day of the week: \"mon\" to \"sun\"\n",
    "   5. FFMC - FFMC index from the FWI system: 18.7 to 96.20\n",
    "   6. DMC - DMC index from the FWI system: 1.1 to 291.3 \n",
    "   7. DC - DC index from the FWI system: 7.9 to 860.6 \n",
    "   8. ISI - ISI index from the FWI system: 0.0 to 56.10\n",
    "   9. temp - temperature in Celsius degrees: 2.2 to 33.30\n",
    "   10. RH - relative humidity in %: 15.0 to 100\n",
    "   11. wind - wind speed in km/h: 0.40 to 9.40 \n",
    "   12. rain - outside rain in mm/m2 : 0.0 to 6.4 \n",
    "   13. area - the burned area of the forest (in ha): 0.00 to 1090.84 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['area'])\n",
    "data['area'] = np.log((1 + data['area']))\n",
    "    \n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the description states the model skews towards the 0.0 a logaithmic transform might be a possible way to normailze the data and reduce the redundancy caused by the skew towards 0.0\n",
    "The log transformation can be used to make highly skewed distributions less skewed. This can be valuable both for making patterns in the data more interpretable and for helping to meet the assumptions of inferential statistics.\n",
    "It can be used to increase or reduce the skew or normalize the data\n",
    "In this case the data which on a scatter plot would have huddled up on the left due to the range and data points being unproportionate will now be spread out on the plot due normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = sb.pairplot(data = data,y_vars=['area'],x_vars=['X','Y','FFMC','DMC','DC','ISI','temp','RH','wind','rain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. X and Y need to be carefully observed as they are cordinates, and they only show the currently burnt area.\n",
    "2. FFMC,DMC,DC,ISI - FWI, indexes (forest fire weather index). ISI and FFMC are not evenly distributed hence they can be said to have an important role in the fire as compared to the rest which seem to be by-products of the fire.\n",
    "3. Wind seems to have made an even impact on the fire. \n",
    "4. Rain seems to have the least co-relation with fire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = sb.swarmplot(x = \"month\", y = \"area\",data = data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1 = sb.swarmplot(x = \"day\", y = \"area\",data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot it seems that the forest fire was maximum in the month of august and september. The days that fire was maximum seems to be saturday and sunday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B (iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = sb.pairplot(data = data,y_vars=['FFMC','DMC','DC','ISI'],x_vars=['temp','RH','wind','rain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B (v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "description = data.describe()\n",
    "mean = pd.DataFrame(description.ix[1])\n",
    "med = pd.DataFrame.median(data)\n",
    "ranges = pd.DataFrame(description.loc['max'] - description.loc['min'])\n",
    "first = pd.DataFrame(description.ix[4])\n",
    "third = pd.DataFrame(description.ix[6])\n",
    "iqr = pd.DataFrame(description.loc['75%'] - description.loc['25%'])\n",
    "table = pd.concat([mean,med,first,third,ranges,iqr,],axis = 1)\n",
    "table.columns = ['mean','median','first','third','ranges','iqr']\n",
    "print (table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature set\n",
    "# Preffered to use Label Encoder as opposed to One-Hot encoding to stop from having increased dimensionality \n",
    "#One hot codoing did not lead to any significant change in result and ols model will by default\n",
    "#give results in one-hot encoded format.\n",
    "lb_make = LabelEncoder()\n",
    "data[\"month_val\"] = lb_make.fit_transform(data[\"month\"])\n",
    "data[\"day_val\"] = lb_make.fit_transform(data[\"day\"])\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "predictors = data.drop(labels=['area','month','day'],axis = 1)\n",
    "target = data.area\n",
    "x_train,x_test,y_train,y_test =train_test_split(predictors,target,test_size = 0.2,random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Area\n",
    "#stat\n",
    "lmx_stat = smf.ols(formula = 'area ~ X ',data = data).fit()\n",
    "print(lmx_stat.params)\n",
    "print(lmx_stat.summary())\n",
    "#sklearn\n",
    "model_x_a = reg.fit((x_train.X).values.reshape(-1,1),y_train)\n",
    "a = model_x_a.predict((x_test.X).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_x_a.coef_)\n",
    "xhold = model_x_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.X, y_test,  color='black')\n",
    "plt.plot(x_test.X, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y and Area\n",
    "#stat\n",
    "lmy_stat = smf.ols(formula = 'area ~ Y',data = data).fit()\n",
    "print(lmy_stat.params)\n",
    "print(lmy_stat.summary())\n",
    "#sklearn\n",
    "model_y_a = reg.fit((x_train.Y).values.reshape(-1,1),y_train)\n",
    "a = model_x_a.predict((x_test.Y).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_y_a.coef_)\n",
    "yhold = model_y_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.Y, y_test,  color='black')\n",
    "plt.plot(x_test.Y, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month_val and Area\n",
    "#stat\n",
    "lmm_stat = smf.ols(formula = 'area ~ month_val',data = data).fit()\n",
    "print(lmm_stat.params)\n",
    "print(lmm_stat.summary())\n",
    "#sklearn\n",
    "model_m_a = reg.fit((x_train.month_val).values.reshape(-1,1),y_train)\n",
    "a = model_m_a.predict((x_test.month_val).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_m_a.coef_)\n",
    "mhold = model_m_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.month_val, y_test,  color='black')\n",
    "plt.plot(x_test.month_val, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day_val and Area\n",
    "lmd_stat = smf.ols(formula = 'area ~ day_val',data = data).fit()\n",
    "print(lmd_stat.params)\n",
    "print(lmd_stat.summary())\n",
    "#sklearn\n",
    "model_d_a = reg.fit((x_train.day_val).values.reshape(-1,1),y_train)\n",
    "a = model_d_a.predict((x_test.day_val).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_d_a.coef_)\n",
    "dhold = model_d_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.day_val, y_test,  color='black')\n",
    "plt.plot(x_test.day_val, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffmc and Area\n",
    "lmf_stat = smf.ols(formula = 'area ~ FFMC',data = data).fit()\n",
    "print(lmf_stat.params)\n",
    "print(lmf_stat.summary())\n",
    "#sklearn\n",
    "model_f_a = reg.fit((x_train.FFMC).values.reshape(-1,1),y_train)\n",
    "a = model_m_a.predict((x_test.FFMC).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_f_a.coef_)\n",
    "fhold = model_f_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.FFMC, y_test,  color='black')\n",
    "plt.plot(x_test.FFMC, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dmc and Area\n",
    "lmdm_stat = smf.ols(formula = 'area ~ DMC',data = data).fit()\n",
    "print(lmdm_stat.params)\n",
    "print(lmdm_stat.summary())\n",
    "#sklearn\n",
    "model_dm_a = reg.fit((x_train.DMC).values.reshape(-1,1),y_train)\n",
    "a = model_dm_a.predict((x_test.DMC).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_dm_a.coef_)\n",
    "dmhold = model_dm_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.DMC, y_test,  color='black')\n",
    "plt.plot(x_test.DMC, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dc and Area\n",
    "lmdc_stat = smf.ols(formula = 'area ~ DC',data = data).fit()\n",
    "print(lmdc_stat.params)\n",
    "print(lmdc_stat.summary())\n",
    "#sklearn\n",
    "model_dc_a = reg.fit((x_train.DC).values.reshape(-1,1),y_train)\n",
    "a = model_dc_a.predict((x_test.DC).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_dc_a.coef_)\n",
    "dchold = model_dc_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.DC, y_test,  color='black')\n",
    "plt.plot(x_test.DC, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isi and Area\n",
    "lmi_stat = smf.ols(formula = 'area ~ ISI',data = data).fit()\n",
    "print(lmi_stat.params)\n",
    "print(lmi_stat.summary())\n",
    "#sklearn\n",
    "model_i_a = reg.fit((x_train.ISI).values.reshape(-1,1),y_train)\n",
    "a = model_m_a.predict((x_test.ISI).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_i_a.coef_)\n",
    "ihold = model_i_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.ISI, y_test,  color='black')\n",
    "plt.plot(x_test.ISI, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp and Area\n",
    "lmt_stat = smf.ols(formula = 'area ~ temp',data = data).fit()\n",
    "print(lmt_stat.params)\n",
    "print(lmt_stat.summary())\n",
    "#sklearn\n",
    "model_t_a = reg.fit((x_train.temp).values.reshape(-1,1),y_train)\n",
    "a = model_m_a.predict((x_test.temp).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_t_a.coef_)\n",
    "thold = model_t_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.temp, y_test,  color='black')\n",
    "plt.plot(x_test.temp, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rh and Area\n",
    "lmrh_stat = smf.ols(formula = 'area ~ RH',data = data).fit()\n",
    "print(lmrh_stat.params)\n",
    "print(lmrh_stat.summary())\n",
    "#sklearn\n",
    "model_rh_a = reg.fit((x_train.RH).values.reshape(-1,1),y_train)\n",
    "a = model_rh_a.predict((x_test.RH).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_rh_a.coef_)\n",
    "rhhold = model_rh_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.RH, y_test, color='black')\n",
    "plt.plot(x_test.RH, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind and Area\n",
    "lmw_stat = smf.ols(formula = 'area ~ wind',data = data).fit()\n",
    "print(lmw_stat.params)\n",
    "print(lmw_stat.summary())\n",
    "#sklearn\n",
    "model_w_a = reg.fit((x_train.wind).values.reshape(-1,1),y_train)\n",
    "a = model_w_a.predict((x_test.wind).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_w_a.coef_)\n",
    "whold = model_w_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.wind, y_test, color='black')\n",
    "plt.plot(x_test.wind, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rain and Area\n",
    "lmra_stat = smf.ols(formula = 'area ~ rain',data = data).fit()\n",
    "print(lmra_stat.params)\n",
    "print(lmra_stat.summary())\n",
    "#sklearn\n",
    "model_ra_a = reg.fit((x_train.rain).values.reshape(-1,1),y_train)\n",
    "a = model_ra_a.predict((x_test.rain).values.reshape(-1,1))\n",
    "print('Coefficients: \\n', model_ra_a.coef_)\n",
    "rahold = model_ra_a.coef_\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, a))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, a))\n",
    "# Plot outputs\n",
    "plt.scatter(x_test.rain, y_test,  color='black')\n",
    "plt.plot(x_test.rain, a, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, Each and every predictor has atleast one value that can be classified as an outlier, this can be observed by looking at the scatter plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All predictors intact\n",
    "lm = reg.fit(x_train,y_train)\n",
    "y_pred = lm.predict(x_test)\n",
    "print(lm.intercept_)\n",
    "#list(zip(train_x, lm.coef_))\n",
    "lm_stat = smf.ols(formula = 'area ~ X + Y + month_val + day_val + FFMC + DMC + DC + ISI + temp + RH + wind + rain',data = data).fit()\n",
    "lm_stat.params\n",
    "print(lm_stat.summary())\n",
    "coeffecient = lm.coef_\n",
    "print('Coefficients: \\n', lm.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "y = lm.coef_\n",
    "x = [lmx_stat.params.X,lmy_stat.params.Y,lmf_stat.params.FFMC,lmdm_stat.params.DMC,lmdc_stat.params.DC,lmi_stat.params.ISI,lmt_stat.params.temp,lmrh_stat.params.RH,lmw_stat.params.wind,lmra_stat.params.rain,lmm_stat.params.month_val,lmd_stat.params.day_val,]\n",
    "print (x)\n",
    "print (y)\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It can be noted that all the predictors have a non-significant p value. Except wind null value hypothesis cannont be rejected for any of the given predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_lotx = [xhold,yhold,mhold,dhold,fhold,dmhold,dchold,ihold,thold,rhhold,whold,rahold]\n",
    "flattened = [val for sublist in e_lotx for val in sublist]\n",
    "e_loty = lm.coef_\n",
    "plt.scatter(e_lotx,e_loty)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = pd.DataFrame()\n",
    "temp_data = data\n",
    "temp_data = temp_data.drop(labels = ['day','month'],axis = 1)\n",
    "for heads in temp_data.columns:\n",
    "    parameter = heads\n",
    "    print(parameter)\n",
    "    new_data = pd.DataFrame()\n",
    "    new_data ['single'] = temp_data[parameter]\n",
    "    new_data['squared'] = (temp_data[parameter]**2)\n",
    "    new_data['cubed'] = (temp_data[parameter]**3)\n",
    "    new_data['area'] = (temp_data['area'])\n",
    "    lmass_stat = smf.ols(formula = 'area ~ single + squared + cubed',data = new_data).fit()\n",
    "    lmass_stat.params\n",
    "    print(lmass_stat.summary())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha = []\n",
    "s = \"\"\n",
    "final_alpha = []\n",
    "temp_holder = []\n",
    "alpha = data.columns\n",
    "alpha = alpha.drop(labels=['area','month_val','day_val'])\n",
    "combs=itertools.combinations(alpha, 2)\n",
    "comb_list = [ list(t) for t in combs ]\n",
    "for i in range(0, len(comb_list)):\n",
    "    holder = \"*\".join(comb_list[i])\n",
    "    temp_holder.append(holder)\n",
    "for j in range (0,len(temp_holder)):\n",
    "    s+=str(temp_holder[j])\n",
    "    s+= str(\"+\")\n",
    "\n",
    "s= s[:-1]    \n",
    "lmgk_stat = smf.ols(formula = 'area ~ {} '.format(s),data = data).fit()\n",
    "lmgk_stat.params\n",
    "print(lmgk_stat.summary())\n",
    "print (\"The following pairs had a significant interaction month_val & day_val , month_val & FFMC, day_val & DC, day_val & DMC, month_val & DC, month_val & ISI, DC & temp, DC & RH  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = pd.DataFrame()\n",
    "new_dataset = data\n",
    "new_dataset = new_dataset.drop(labels = ['X','Y','rain','wind'], axis = 1)\n",
    "new_dataset['month_val&day_val'] = (data.month_val * data.day_val)\n",
    "new_dataset['month_val&FFMC'] = (data.month_val * data.FFMC)\n",
    "new_dataset['day_val&DMC'] = (data.day_val * data.DMC)\n",
    "new_dataset['month_val&DC'] = (data.month_val * data.DC)\n",
    "new_dataset['month_val&ISI'] = (data.month_val * data.ISI)\n",
    "new_dataset['DCtemp'] = (data.DC * data.temp) \n",
    "new_dataset['day_valDC'] = (data.day_val * data.DC)\n",
    "new_dataset['DCRH'] = (data.DC * data.RH) \n",
    "\n",
    "lmgk_stat = smf.ols(formula = 'area ~ FFMC + DMC + DC + ISI + temp + RH + month_val + day_val + month_val&day_val + month_val&FFMC + day_valDC + day_val&DMC + month_val&DC + month_val&ISI+ DCtemp + DCRH ',data = new_dataset).fit()\n",
    "lmgk_stat.params\n",
    "print(lmgk_stat.summary())\n",
    "\n",
    "new_target = new_dataset.area\n",
    "new_predictor = new_dataset.drop(labels =['area', 'day', 'month'], axis = 1)\n",
    "ntrain_errors = list()\n",
    "ntest_errors = list()\n",
    "x_ntrain,x_ntest,y_ntrain,y_ntest =train_test_split(new_predictor,new_target,test_size = 0.3,random_state = 4)\n",
    "olsmod = sm.OLS(y_ntrain, x_ntrain)\n",
    "olsres = olsmod.fit()\n",
    "print(olsres.summary)\n",
    "ypredtest = olsres.predict(x_ntest)\n",
    "ypredtrain = olsres.predict(x_ntrain)\n",
    "ntrain_errors.append(mean_squared_error(ypredtrain,y_ntrain))\n",
    "ntest_errors.append(mean_squared_error(ypredtest,y_ntest))\n",
    "\n",
    "print (\"Below are the value of train and test errors\")\n",
    "print(ntrain_errors,ntest_errors)\n",
    "\n",
    "\n",
    "plt.plot(train_errors,'g')\n",
    "plt.plot(test_errors,'r')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Regression using first four predictors\n",
    "x_train_ff = x_train.drop(labels=['FFMC','DMC','DC','ISI','temp','RH','wind','rain'],axis = 1)\n",
    "y_train_ff = y_train\n",
    "x_test_ff = x_test.drop(labels=['FFMC','DMC','DC','ISI','temp','RH','wind','rain'],axis = 1)\n",
    "y_test_ff = y_test\n",
    "train_errors = list()\n",
    "test_errors =list()\n",
    "klist = [1,3,5,7,8,10]\n",
    "for k in klist:\n",
    "    neigh = KNeighborsRegressor(k)\n",
    "    neigh.fit(x_train_ff,y_train_ff)\n",
    "    y_pred_train = neigh.predict(x_train_ff)\n",
    "    y_pred_test = neigh.predict(x_test_ff)    \n",
    "    train_errors.append(mean_squared_error(y_pred_train,y_train_ff))\n",
    "    test_errors.append(mean_squared_error(y_pred_test,y_test_ff))\n",
    "\n",
    "print(train_errors,test_errors)\n",
    "\n",
    "onebyklist=[1,1/3,1/5,1/7,1/8,1/10]\n",
    "plt.plot(onebyklist, train_errors,'g')\n",
    "plt.plot(onebyklist, test_errors,'r')\n",
    "plt.show()\n",
    "\n",
    "print (\"The best value of the result comes when k is 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Regression using last four predictors\n",
    "x_train_ff = x_train.drop(labels=['FFMC','DMC','DC','ISI','X','Y','day_val','month_val'],axis = 1)\n",
    "y_train_ff = y_train\n",
    "x_test_ff = x_test.drop(labels=['FFMC','DMC','DC','ISI','X','Y','day_val','month_val'],axis = 1)\n",
    "y_test_ff = y_test\n",
    "train_errors = list()\n",
    "test_errors =list()\n",
    "klist = [1,3,5,7,8,10]\n",
    "for k in klist:\n",
    "    neigh = KNeighborsRegressor(k)\n",
    "    neigh.fit(x_train_ff,y_train_ff)\n",
    "    y_pred_train = neigh.predict(x_train_ff)\n",
    "    y_pred_test = neigh.predict(x_test_ff)    \n",
    "    train_errors.append(mean_squared_error(y_pred_train,y_train_ff))\n",
    "    test_errors.append(mean_squared_error(y_pred_test,y_test_ff))\n",
    "\n",
    "print(train_errors,test_errors)\n",
    "\n",
    "onebyklist=[1,1/3,1/5,1/7,1/8,1/10]\n",
    "plt.plot(onebyklist, train_errors,'g')\n",
    "plt.plot(onebyklist, test_errors,'r')\n",
    "plt.show()\n",
    "\n",
    "print(\"The value of K that gives the best result is 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Regression using 1,2,9,10,11 predictors x,y,temp,rh,wind \n",
    "x_train_ff = x_train.drop(labels=['rain','FFMC','DMC','DC','ISI','day_val','month_val'],axis = 1)\n",
    "y_train_ff = y_train\n",
    "x_test_ff = x_test.drop(labels=['rain','FFMC','DMC','DC','ISI','day_val','month_val'],axis = 1)\n",
    "y_test_ff = y_test\n",
    "train_errors = list()\n",
    "test_errors =list()\n",
    "klist = [1,3,5,7,8,10]\n",
    "for k in klist:\n",
    "    neigh = KNeighborsRegressor(k)\n",
    "    neigh.fit(x_train_ff,y_train_ff)\n",
    "    y_pred_train = neigh.predict(x_train_ff)\n",
    "    y_pred_test = neigh.predict(x_test_ff)    \n",
    "    train_errors.append(mean_squared_error(y_pred_train,y_train_ff))\n",
    "    test_errors.append(mean_squared_error(y_pred_test,y_test_ff))\n",
    "\n",
    "#print(train_errors,test_errors)\n",
    "\n",
    "onebyklist=[1,1/3,1/5,1/7,1/8,1/10]\n",
    "plt.plot(onebyklist, train_errors,'g')\n",
    "plt.plot(onebyklist, test_errors,'r')\n",
    "plt.show()\n",
    "\n",
    "best_k = 1\n",
    "train_errors_best = list()\n",
    "test_errors_best =list()\n",
    "best = KNeighborsRegressor(best_k)\n",
    "best.fit(x_train_ff,y_train_ff)\n",
    "y_pred_train_best = neigh.predict(x_train_ff)\n",
    "y_pred_test_best = neigh.predict(x_test_ff)    \n",
    "train_errors_best.append(mean_squared_error(y_pred_train_best,y_train_ff))\n",
    "test_errors_best.append(mean_squared_error(y_pred_test_best,y_test_ff))\n",
    "print (\"Below are the train error , test error \")\n",
    "print(train_errors_best,test_errors_best)\n",
    "print (\"Below are the r squared of train and test\")\n",
    "print(r2_score(y_pred_train_best,y_train_ff))\n",
    "print(r2_score(y_pred_test_best,y_test_ff))\n",
    "\n",
    "print (\"The best value of K for which the error is the least is 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Comparison between the best case of KNN Regression and best case Linear Regression\n",
    "The points of comparison are selected as follows\n",
    "1. Error measures in the estimation period : For our analysis we will be using mean squared error\n",
    "2. Error measures in the validation period : For our analysis we will be using mean squared error\n",
    "3. Residual diagnostics and goodness-of-fit tests: Using R squared value\n",
    "4. Qualitative considerations: intuitive reasonableness of the model, simplicity of the model, and above all, usefulness for decision making!\n",
    "\n",
    "KNN Regression:\n",
    "1. Train Error :    1.66\n",
    "2. Test Error  :    2.19\n",
    "3. R-Squared Value :-7.90\n",
    "\n",
    "Linear Regression :\n",
    "1. Train Error :     1.84\n",
    "2. Test Error  :     2.05\n",
    "3. R-Squared Value : 0.027\n",
    "\n",
    "Based on the above performance parameters it can be said that Linear Regressions using pair/interaction predictors yield a better result. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
